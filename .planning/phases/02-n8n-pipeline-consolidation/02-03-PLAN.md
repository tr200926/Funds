---
phase: 02-n8n-pipeline-consolidation
plan: 03
type: execute
wave: 2
depends_on: ["02-01", "02-02"]
files_modified:
  - n8n-workflows/controller.json
  - n8n-workflows/error-handler.json
autonomous: false

must_haves:
  truths:
    - "Controller workflow triggers on a schedule (every 3 hours)"
    - "Controller calls Facebook Ingestion, TikTok 1, and TikTok 2 sub-workflows sequentially"
    - "Controller passes org_id and pipeline_name to each sub-workflow"
    - "If a sub-workflow fails, the Controller continues to the next (does not abort)"
    - "Controller creates its own pipeline_run entry for observability"
    - "A separate Error Handler workflow catches unhandled failures and marks pipeline_runs as 'failed'"
    - "All 4 workflows together produce identical data to the old 8 workflows"
    - "Zero Google Sheets writes across all workflows"
  artifacts:
    - path: "n8n-workflows/controller.json"
      provides: "Controller workflow that orchestrates all 3 ingestion sub-workflows"
      contains: "Schedule Trigger"
    - path: "n8n-workflows/error-handler.json"
      provides: "Global error handler workflow for pipeline failure recovery"
      contains: "Error Trigger"
  key_links:
    - from: "controller.json (Execute Sub-workflow nodes)"
      to: "facebook-ingestion.json, tiktok-ingestion-1.json, tiktok-ingestion-2.json"
      via: "Execute Sub-workflow node calls with typed inputs"
      pattern: "executeSubWorkflow"
    - from: "controller.json (Schedule Trigger)"
      to: "Recurring execution"
      via: "Cron schedule every 3 hours"
      pattern: "scheduleTrigger"
    - from: "controller.json (Node 6: Aggregate Sub-workflow Results)"
      to: "facebook-ingestion, tiktok-ingestion-1, tiktok-ingestion-2 return values"
      via: "Access $('Execute Facebook Ingestion').first().json.status and .pipeline_run_id"
      pattern: "node reference expressions"
    - from: "error-handler.json (Error Trigger)"
      to: "pipeline_runs table"
      via: "Updates stuck 'running' pipeline_runs to 'failed'"
      pattern: "Error Trigger"
---

<objective>
Build the Controller workflow that orchestrates all 3 ingestion sub-workflows on a 3-hour schedule, plus a global Error Handler workflow for pipeline failure recovery. Then verify the complete 4-workflow system end-to-end.

Purpose: The Controller is the single entry point for all data ingestion. It replaces the old 2 separate controller workflows and ensures all ingestion runs are coordinated. The Error Handler catches any unhandled workflow failures and ensures pipeline_runs never get stuck in 'running' status indefinitely.

Output: Two importable n8n workflow JSON files (controller + error handler) and a verified complete pipeline system.
</objective>

<execution_context>
@C:/Users/hossa/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/hossa/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/02-n8n-pipeline-consolidation/02-RESEARCH.md
@.planning/phases/02-n8n-pipeline-consolidation/02-01-SUMMARY.md
@.planning/phases/02-n8n-pipeline-consolidation/02-02-SUMMARY.md
@supabase/migrations/20260212000001_create_core_schema.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Controller and Error Handler workflow JSONs</name>
  <files>n8n-workflows/controller.json, n8n-workflows/error-handler.json</files>
  <action>
**Part A: Controller Workflow (controller.json)**

Create a complete n8n workflow JSON for the Controller with this node chain:

**Node 1: Schedule Trigger**
- Trigger interval: every 3 hours
- Rule: Cron expression `0 */3 * * *` (every 3 hours on the hour)

**Node 2: Create Controller Pipeline Run (Supabase INSERT)**
- Table: `pipeline_runs`
- Fields: org_id='00000000-0000-0000-0000-000000000001', pipeline_name='controller', status='running', started_at=now(), metadata={ n8n_execution_id: $execution.id, sub_workflows: ['facebook_ingestion', 'tiktok_ingestion_1', 'tiktok_ingestion_2'] }

**Node 3: Execute Facebook Ingestion (Execute Sub-workflow)**
- Target: facebook-ingestion workflow (by workflow ID -- use placeholder ID that user replaces after import)
- Input: { org_id: '00000000-0000-0000-0000-000000000001', pipeline_name: 'facebook_ingestion' }
- Wait for sub-workflow to complete: YES
- Continue on Error: YES (so TikTok workflows still run if Facebook fails)

**Node 4: Execute TikTok Ingestion 1 (Execute Sub-workflow)**
- Target: tiktok-ingestion-1 workflow (placeholder ID)
- Input: { org_id: '00000000-0000-0000-0000-000000000001', pipeline_name: 'tiktok_ingestion_1' }
- Wait for sub-workflow to complete: YES
- Continue on Error: YES

**Node 5: Execute TikTok Ingestion 2 (Execute Sub-workflow)**
- Target: tiktok-ingestion-2 workflow (placeholder ID)
- Input: { org_id: '00000000-0000-0000-0000-000000000001', pipeline_name: 'tiktok_ingestion_2' }
- Wait for sub-workflow to complete: YES
- Continue on Error: YES

**Node 6: Aggregate Sub-workflow Results (Code node)**
- Collect return values from Nodes 3, 4, 5 using n8n node reference expressions:
  - const fbResult = $('Execute Facebook Ingestion').first().json;
  - const tiktok1Result = $('Execute TikTok Ingestion 1').first().json;
  - const tiktok2Result = $('Execute TikTok Ingestion 2').first().json;
- Extract status and pipeline_run_id from each result:
  - fbResult.status, fbResult.pipeline_run_id
  - tiktok1Result.status, tiktok1Result.pipeline_run_id
  - tiktok2Result.status, tiktok2Result.pipeline_run_id
- Count which sub-workflows succeeded, failed, or returned partial
- Build summary: { facebook: 'success'|'failed'|'error', tiktok_1: ..., tiktok_2: ... }
- Determine controller status: 'success' (all succeeded), 'partial' (some failed), 'failed' (all failed)
- Count total accounts_processed and accounts_failed across all sub-workflows

**Node 7: Finalize Controller Pipeline Run (Supabase UPDATE)**
- Table: `pipeline_runs`
- Filter: id = pipeline_run_id from Node 2
- Fields: status (from Node 6), completed_at=now(), accounts_processed (total), accounts_failed (total), metadata (merge sub-workflow summary)

**Execution flow:** The three Execute Sub-workflow nodes (3, 4, 5) run SEQUENTIALLY (not parallel). This avoids overwhelming the Supabase instance and ensures cleaner pipeline_runs logging. Connect them in chain: 3 -> 4 -> 5.

**Workflow settings:**
- Timezone: Africa/Cairo
- Error Workflow: error-handler workflow (configurable after import)

---

**Part B: Error Handler Workflow (error-handler.json)**

Create a separate n8n workflow for global error handling:

**Node 1: Error Trigger**
- This fires when ANY workflow in the n8n instance fails (if that workflow has this one set as its Error Workflow)

**Node 2: Extract Failure Info (Code node)**
- From the error trigger payload, extract:
  - workflow.id (which workflow failed)
  - workflow.name
  - execution.id
  - execution.error (error message)
  - timestamp

**Node 3: Find Stuck Pipeline Runs (Supabase SELECT)**
- Table: `pipeline_runs`
- Filter: status = 'running', started_at < (now - 30 minutes)
- This catches any pipeline_run that was created but never finalized due to a crash

**Node 4: Mark Failed Pipeline Runs (Supabase UPDATE)**
- For each stuck pipeline_run from Node 3:
- Update: status='failed', completed_at=now(), error_log={ unhandled_crash: true, workflow_name: (from Node 2), execution_id: (from Node 2), error: (from Node 2) }

**Workflow settings:**
- This workflow should be set as the Error Workflow for all 4 other workflows
- Timezone: Africa/Cairo
- Active: true (always running)

**Important notes for both workflows:**
- Zero Google Sheets nodes (R3.4)
- No hardcoded credentials or tokens
- The Controller uses placeholder sub-workflow IDs that must be updated after import (document in README -- already handled by Plan 01 Task 2)
  </action>
  <verify>
1. Validate controller JSON: `node -e "const w = require('./n8n-workflows/controller.json'); console.log('Controller nodes:', w.nodes?.length)"`
2. Validate error handler JSON: `node -e "const w = require('./n8n-workflows/error-handler.json'); console.log('Error handler nodes:', w.nodes?.length)"`
3. Verify Controller has Schedule Trigger: search for "scheduleTrigger" or "Schedule Trigger"
4. Verify Controller has 3 Execute Sub-workflow nodes
5. Verify Controller has Continue on Error on all sub-workflow calls
6. Verify Error Handler has Error Trigger node
7. Verify no Google Sheets references in either file
8. Verify all 5 workflow files exist in n8n-workflows/: controller.json, error-handler.json, facebook-ingestion.json, tiktok-ingestion-1.json, tiktok-ingestion-2.json
  </verify>
  <done>
Two valid n8n workflow JSON files exist:
- controller.json: Schedule Trigger (every 3h) -> calls Facebook, TikTok 1, TikTok 2 sequentially -> aggregates results -> logs to pipeline_runs
- error-handler.json: Error Trigger -> finds stuck pipeline_runs -> marks them as 'failed'
- Both contain zero Google Sheets nodes
- Controller uses Continue on Error so one sub-workflow failure doesn't block the others
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify complete workflow system</name>
  <files>n8n-workflows/controller.json, n8n-workflows/error-handler.json, n8n-workflows/facebook-ingestion.json, n8n-workflows/tiktok-ingestion-1.json, n8n-workflows/tiktok-ingestion-2.json, n8n-workflows/README.md</files>
  <action>
Present the complete workflow system to the user for verification. The user should review all 5 workflow JSON files and the README to confirm the system meets all R3.x requirements before proceeding to import into the n8n instance.

What was built: Complete n8n pipeline consolidation -- 5 workflow JSON files (Controller, Facebook Ingestion, TikTok Ingestion 1, TikTok Ingestion 2, Error Handler) that replace the old 8 workflows. All workflows write to the new normalized Supabase schema (pipeline_runs, spend_records, balance_snapshots, ad_accounts) and maintain dual-write to legacy tables during the validation period.

How to verify:

Step 1: Review workflow files -- check that all 5 JSON files exist in n8n-workflows/.

Step 2: Verify key requirements are met:
- R3.1: 4 main workflows (controller + 3 ingestion) exist -- down from 8
- R3.2: All Facebook API URLs use v23.0
- R3.3: pipeline_runs INSERT + UPDATE lifecycle in every ingestion workflow
- R3.4: Zero "Google Sheets" or "googleSheets" references in any workflow
- R3.5: All Code nodes use setZone('Africa/Cairo'), no manual UTC offsets
- R3.6: Dual-write nodes present in all ingestion workflows
- R3.7: Facebook balance divided by 100, TikTok balance NOT divided
- R3.8: Facebook uses batch API (HTTP Request POST with batch body)

Step 3: Review README import instructions and confirm credential requirements, import order, and validation checklist are documented.

Resume signal: Type "approved" to confirm the workflow system is ready, or describe issues that need fixing.
  </action>
  <verify>User confirms all R3.x requirements are satisfied and the workflow system is ready for import into n8n.</verify>
  <done>User has approved the complete 5-workflow system, confirming it meets all R3.1-R3.8 requirements and is ready for n8n import and validation.</done>
</task>

</tasks>

<verification>
- All 5 workflow JSON files exist and are valid
- Controller triggers every 3 hours and calls all 3 ingestion workflows
- Error Handler catches failures and marks stuck pipeline_runs as 'failed'
- Complete system satisfies all R3.x requirements
- README provides actionable setup guide
</verification>

<success_criteria>
- 5 workflow JSON files in n8n-workflows/ directory
- Controller orchestrates Facebook + TikTok 1 + TikTok 2 sequentially
- Error Handler recovers from unhandled crashes
- All R3.1-R3.8 requirements verifiably met across the workflow set
- User approves the complete system at checkpoint
</success_criteria>

<output>
After completion, create `.planning/phases/02-n8n-pipeline-consolidation/02-03-SUMMARY.md`
</output>
