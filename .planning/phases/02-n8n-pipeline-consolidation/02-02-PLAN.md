---
phase: 02-n8n-pipeline-consolidation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - n8n-workflows/tiktok-ingestion-1.json
  - n8n-workflows/tiktok-ingestion-2.json
autonomous: true

must_haves:
  truths:
    - "TikTok Ingestion 1 workflow reads active TikTok ad_accounts for token group 1 from Supabase"
    - "TikTok Ingestion 2 workflow reads active TikTok ad_accounts for token group 2 from Supabase"
    - "Each workflow uses its own dedicated credential (no dynamic credential switching)"
    - "TikTok API calls use v1.3 endpoints (business-api.tiktok.com/open_api/v1.3/)"
    - "TikTok monetary values are NOT divided by 100 (no micro-unit conversion for TikTok)"
    - "All date calculations use Luxon setZone('Africa/Cairo')"
    - "Each workflow creates and finalizes a pipeline_run with per-account error tracking"
    - "Workflow upserts spend_records and inserts balance_snapshots"
    - "Workflow writes to legacy TikTok tables for dual-write validation"
    - "Workflow does NOT write to Google Sheets"
    - "Per-account errors are caught and logged without stopping the batch"
  artifacts:
    - path: "n8n-workflows/tiktok-ingestion-1.json"
      provides: "Complete n8n workflow JSON for TikTok token group 1 ingestion"
      contains: "Execute Sub-workflow Trigger"
    - path: "n8n-workflows/tiktok-ingestion-2.json"
      provides: "Complete n8n workflow JSON for TikTok token group 2 ingestion"
      contains: "Execute Sub-workflow Trigger"
  key_links:
    - from: "tiktok-ingestion-1.json (Execute Sub-workflow Trigger)"
      to: "Controller workflow"
      via: "Execute Sub-workflow node call with typed inputs (org_id, pipeline_name)"
      pattern: "executeSubWorkflowTrigger"
    - from: "tiktok-ingestion-1.json (HTTP Request nodes)"
      to: "TikTok Business API v1.3"
      via: "GET requests to business-api.tiktok.com/open_api/v1.3/"
      pattern: "business-api.tiktok.com"
    - from: "tiktok-ingestion-1.json (Supabase nodes)"
      to: "pipeline_runs, spend_records, balance_snapshots tables"
      via: "n8n Supabase node upsert/insert operations"
      pattern: "supabase"
---

<objective>
Build the two TikTok Ingestion n8n workflows (one per API token group) that replace the 2 old TikTok sub-workflows. Each workflow fetches advertiser info, balance, and spend data from the TikTok Business API v1.3 and writes to the new normalized tables.

Purpose: TikTok requires 2 separate workflows because the platform uses 2 different access tokens for different groups of advertiser accounts. n8n credential selection via expressions is fragile, so dedicated workflows with hardcoded credentials are more reliable. Unlike Facebook, TikTok has no batch API, so each account is processed individually with per-account error handling.

Output: Two importable n8n workflow JSON files (structurally identical except for credential reference and pipeline_name).
</objective>

<execution_context>
@C:/Users/hossa/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/hossa/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/02-n8n-pipeline-consolidation/02-RESEARCH.md
@supabase/migrations/20260212000001_create_core_schema.sql
@supabase/migrations/20260212000003_create_triggers.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create TikTok Ingestion 1 workflow JSON</name>
  <files>n8n-workflows/tiktok-ingestion-1.json</files>
  <action>
Create a complete n8n workflow JSON file for TikTok Ingestion (Token Group 1). The workflow structure must follow this exact node chain:

**Node 1: Execute Sub-workflow Trigger**
- Input data mode: "Define using fields below"
- Fields: `org_id` (string, default '00000000-0000-0000-0000-000000000001'), `pipeline_name` (string, default 'tiktok_ingestion_1')

**Node 2: Compute Cairo Dates (Code node)**
- Use Luxon: `const cairo = DateTime.now().setZone('Africa/Cairo');`
- Compute: `today`, `yesterday`, `startOfMonth` (all yyyy-MM-dd format)
- Compute: `cairoTimestamp` (ISO string)
- Do NOT use manual UTC+2 or UTC+3 offsets anywhere

**Node 3: Create Pipeline Run (Supabase INSERT)**
- Table: `pipeline_runs`
- Fields: org_id, pipeline_name='tiktok_ingestion_1', status='running', started_at=now(), accounts_processed=0, accounts_failed=0, metadata={ triggered_by: 'controller', n8n_execution_id: $execution.id }
- Capture returned `id` as pipeline_run_id

**Node 4: Fetch Active TikTok Accounts for Group 1 (Supabase SELECT)**
- Table: `ad_accounts`
- Filters: org_id = input org_id, platform_id = 'tiktok', status = 'active'
- Additional filter: metadata->>'token_group' = '1' (to distinguish which accounts belong to this token)
- If no token_group metadata exists yet, an alternative approach is to hardcode the list of advertiser_ids for group 1 in the workflow as a configuration Code node that can be edited. Document this in the README.
- Select: id, platform_account_id, account_name, business_manager, metadata

**Node 5: Loop Over Each Account (SplitInBatches node)**
- Batch size: 1 (process accounts one at a time since TikTok has no batch API)
- This creates a loop that processes each account individually

**Inside the loop (Nodes 6-12):**

**Node 6: Fetch Advertiser Info (HTTP Request)**
- Method: GET
- URL: `https://business-api.tiktok.com/open_api/v1.3/advertiser/info/`
- Query params: `advertiser_ids=["{platform_account_id}"]`
- Authentication: Header Auth credential (Access-Token header) -- credential for Token Group 1
- Continue on Error: true (captures errors for per-account logging)

**Node 7: Fetch Advertiser Balance (HTTP Request)**
- Method: GET
- URL: `https://business-api.tiktok.com/open_api/v1.3/advertiser/balance/get/`
- Query params: `advertiser_ids={platform_account_id}` (NOT array format for this endpoint)
- If account has metadata.bc_id, add query param: `bc_id={metadata.bc_id}`
- Authentication: Same Header Auth credential as Node 6
- Continue on Error: true

**Node 8: Fetch Daily Spend Report (HTTP Request)**
- Method: GET
- URL: `https://business-api.tiktok.com/open_api/v1.3/report/integrated/get/`
- Query params:
  - advertiser_id: `{platform_account_id}`
  - report_type: `BASIC`
  - data_level: `AUCTION_ADVERTISER`
  - dimensions: `["stat_time_day"]`
  - metrics: `["spend"]`
  - start_date: `{yesterday}` (from Node 2)
  - end_date: `{yesterday}`
  - page_size: `10`
- Authentication: Same Header Auth credential
- Continue on Error: true

**Node 9: Fetch MTD Spend Report (HTTP Request)**
- Same as Node 8 but:
  - start_date: `{startOfMonth}` (from Node 2)
  - end_date: `{today}` (from Node 2)
  - page_size: `100`

**Node 10: Normalize TikTok Data (Code node)**
- Parse responses from Nodes 6-9
- Extract: advertiser name, status, balance, available funds, daily spend, MTD spend
- **CRITICAL: Do NOT divide by 100.** TikTok returns values in currency units (not micro-units). This is a key difference from Facebook.
- Map TikTok status to normalized form: 'STATUS_ENABLE'='active', others='disabled'
- For daily spend: sum all `spend` values from the daily report response's `list` array
- For MTD spend: sum all `spend` values from the MTD report response's `list` array
- Build result object with: ad_account_id (UUID from Node 4), platform_account_id, account_name, status, balance, available_funds, daily_spend, mtd_spend, date (Cairo date), captured_at (Cairo ISO), pipeline_run_id
- Build error object if any of Nodes 6-9 returned errors
- Output: { success: true/false, data: {...}, error: string|null }

**Node 11: Upsert spend_records (Supabase UPSERT) -- only if success**
- Table: `spend_records`
- Conflict columns: `ad_account_id,date`
- Fields: org_id, ad_account_id (UUID), date (Cairo date), daily_spend, mtd_spend, currency='EGP', raw_data (original TikTok responses as JSONB), pipeline_run_id

**Node 12: Insert balance_snapshots (Supabase INSERT) -- only if success**
- Table: `balance_snapshots`
- Fields: org_id, ad_account_id (UUID), balance, available_funds (text), currency='EGP', captured_at (Cairo timestamp), pipeline_run_id

**Node 13: Update Legacy TikTok Table - Dual Write (Supabase UPSERT) -- only if success**
- Write to old TikTok legacy table with same columns as the old workflow
- Map: Advertiser_id, Advertiser name, Available funds, Daily spending, Status, BC-ID (from metadata)

**End of loop - back to SplitInBatches**

**Node 14: Aggregate Results (Code node)**
- Collect all per-account results from the loop
- Count successes and failures
- Build error_log JSONB
- Determine final status: 'success'/'partial'/'failed'

**Node 15: Finalize Pipeline Run (Supabase UPDATE)**
- Table: `pipeline_runs`
- Filter: id = pipeline_run_id
- Fields: status, completed_at=now(), accounts_processed, accounts_failed, error_log

**Workflow settings:**
- Error Workflow: configurable after import
- Timezone: Africa/Cairo
- No retry on fail

**Important constraints:**
- All TikTok API calls use v1.3: `business-api.tiktok.com/open_api/v1.3/`
- NO micro-unit conversion (unlike Facebook)
- NO Google Sheets nodes (R3.4)
- Credential referenced by n8n credential ID, not hardcoded tokens
- Header Auth credential type with `Access-Token` header name
  </action>
  <verify>
1. Validate JSON: `node -e "const w = require('./n8n-workflows/tiktok-ingestion-1.json'); console.log('Nodes:', w.nodes?.length)"`
2. Verify no Google Sheets references: search for "googleSheets" or "Google Sheets" -- zero matches
3. Verify TikTok API v1.3: search for "business-api.tiktok.com" -- all must include "v1.3"
4. Verify NO division by 100 in TikTok normalization Code node (unlike Facebook)
5. Verify Luxon timezone usage: search for "setZone" and "Africa/Cairo"
6. Verify pipeline_runs lifecycle: both INSERT and UPDATE present
7. Verify pipeline_name is 'tiktok_ingestion_1'
  </verify>
  <done>
A valid n8n workflow JSON exists at n8n-workflows/tiktok-ingestion-1.json that:
- Has Execute Sub-workflow Trigger with typed inputs
- Calls TikTok Business API v1.3 for advertiser info, balance, and spend reports
- Does NOT divide monetary values (TikTok returns currency units)
- Uses Luxon setZone('Africa/Cairo') for dates
- Processes accounts individually (no batch API for TikTok)
- Creates and finalizes pipeline_run with per-account error tracking
- Writes to spend_records, balance_snapshots, and legacy tables
- Contains zero Google Sheets nodes
  </done>
</task>

<task type="auto">
  <name>Task 2: Create TikTok Ingestion 2 workflow JSON (clone with different credential)</name>
  <files>n8n-workflows/tiktok-ingestion-2.json</files>
  <action>
Create tiktok-ingestion-2.json as a structural clone of tiktok-ingestion-1.json with these specific differences:

1. **Workflow name:** "TikTok Ingestion 2" (not "TikTok Ingestion 1")
2. **Pipeline name:** `tiktok_ingestion_2` in all references (Execute Sub-workflow Trigger default, Create Pipeline Run node)
3. **Credential reference:** All HTTP Request nodes must reference a DIFFERENT n8n credential ID for Token Group 2 (use a placeholder credential name like "TikTok Token Group 2" vs "TikTok Token Group 1" in the workflow JSON)
4. **Account filter:** metadata->>'token_group' = '2' (instead of '1') in the Supabase SELECT node
5. **Node IDs:** All node IDs must be unique (different from tiktok-ingestion-1.json) to avoid conflicts when both workflows are imported into the same n8n instance
6. **Workflow ID:** Must be different from tiktok-ingestion-1.json

Everything else (node structure, Code node logic, Supabase operations, error handling, timezone handling) must be IDENTICAL to tiktok-ingestion-1.json.

To create this:
1. Read the tiktok-ingestion-1.json file
2. Deep-clone the entire structure
3. Replace all instances of "tiktok_ingestion_1" with "tiktok_ingestion_2"
4. Replace all instances of "TikTok Ingestion 1" with "TikTok Ingestion 2"
5. Replace "TikTok Token Group 1" with "TikTok Token Group 2"
6. Replace token_group filter from '1' to '2'
7. Regenerate all node IDs (UUIDs) to be unique
8. Write the result
  </action>
  <verify>
1. Validate JSON: `node -e "const w = require('./n8n-workflows/tiktok-ingestion-2.json'); console.log('Nodes:', w.nodes?.length)"`
2. Verify pipeline_name is 'tiktok_ingestion_2' (not '1'): search for "tiktok_ingestion_1" -- zero matches
3. Verify credential reference differs from tiktok-ingestion-1.json: search for "Token Group 2"
4. Verify token_group filter is '2': search for "token_group"
5. Verify no shared node IDs between the two TikTok workflow files
6. Verify no Google Sheets references
7. Verify Luxon timezone usage present
  </verify>
  <done>
A valid n8n workflow JSON exists at n8n-workflows/tiktok-ingestion-2.json that is structurally identical to tiktok-ingestion-1.json but:
- Uses pipeline_name 'tiktok_ingestion_2'
- References TikTok Token Group 2 credential
- Filters for token_group '2' accounts
- Has unique node IDs (no conflicts with workflow 1)
- All other behavior (TikTok API calls, normalization, Supabase writes, error handling) is identical
  </done>
</task>

</tasks>

<verification>
- Both TikTok workflow JSON files are valid and importable
- Each uses its own credential reference (Token Group 1 vs Token Group 2)
- Each uses the correct pipeline_name
- TikTok monetary values are NOT divided by 100
- All dates use Luxon setZone('Africa/Cairo')
- Pipeline run lifecycle is complete in both workflows
- Zero Google Sheets references in either workflow
- Dual-write to legacy tables is present
- No shared node IDs between the two workflow files
</verification>

<success_criteria>
- tiktok-ingestion-1.json and tiktok-ingestion-2.json both exist as valid n8n workflow JSON
- Each workflow has ~15 nodes following the documented architecture
- The only differences between them are: workflow name, pipeline_name, credential reference, token_group filter, and node IDs
- No micro-unit conversion applied to TikTok values
- Pipeline runs are logged with per-account error tracking in both workflows
</success_criteria>

<output>
After completion, create `.planning/phases/02-n8n-pipeline-consolidation/02-02-SUMMARY.md`
</output>
